{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "954c90ed",
   "metadata": {},
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18aa4420",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "from urllib.parse import unquote\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import requests\n",
    "import ssl\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.poolmanager import PoolManager\n",
    "from requests.packages.urllib3.util import ssl_\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import unquote\n",
    "from datetime import timedelta, date\n",
    "import re\n",
    "import time\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f60140",
   "metadata": {},
   "source": [
    "## Создаем функции для добычи информации по тегам"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f73c59",
   "metadata": {},
   "source": [
    "Каждая функция будет обращаться к конкретному тегу и доставать оттуда нужную нам информацию. На выходе функции будут выдавать словарь где ключами будут название столбца нашего будущего датафрейма, а значением- значение в столбце."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b48f40d",
   "metadata": {},
   "source": [
    "Функция получения ссылок на объявления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c77e6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(url):\n",
    "    s2=[]\n",
    "    r = session.request('GET', url)\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "    r1=soup.findAll('a')\n",
    "    s2.extend(r1)\n",
    "    links=[]\n",
    "    \n",
    "    for i in s2:\n",
    "        links.append(i.get('href'))\n",
    "    links=set(filter(lambda x: str(x).startswith('/moskva/kvartiry/1') \n",
    "                      or str(x).startswith('/moskva/kvartiry/2') \n",
    "                      or str(x).startswith('/moskva/kvartiry/3') \n",
    "                      or str(x).startswith('/moskva/kvartiry/4') \n",
    "                      or str(x).startswith('/moskva/kvartiry/5')\n",
    "                      or str(x).startswith('/moskva/kvartiry/6')\n",
    "                      or str(x).startswith('/moskva/kvartiry/kvartira-studiya'), links))\n",
    "    \n",
    "    \n",
    "    return links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8305cc07",
   "metadata": {},
   "source": [
    "Функции получения информации о метро, количестве комнат и общей площади, общую информацию(площадь кухни, ремонт), информацию о доме, информацию о цене, дате, адресе, координатах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67a91589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_undeground(soup):\n",
    "    try:\n",
    "        metro = soup.find(class_=re.compile('style-item-address-georeferences-item-TZsrp'))\n",
    "        list_metro=metro.find_all('span')\n",
    "        list_metro=list(filter(lambda x: x!='',list(map(lambda x: x.text.strip(), list_metro))))\n",
    "        name=list_metro[0]\n",
    "        time=list_metro[1]\n",
    "\n",
    "        return {\"metro_name\": name, \"time_to_metro\": time}\n",
    "    except:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c5dd851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(soup):\n",
    "    try:\n",
    "        titles=soup.find('span',{\"data-marker\":re.compile(\"item-view/title-info\")}).text.strip()\n",
    "        title = titles.split(',')\n",
    "        title_list = [title[0],','.join(title[1:-1])]\n",
    "        title_list=list(map(lambda x: x.strip(), title_list))\n",
    "        return {\"num_rooms\": 'Cтудия' if ( title[0].startswith('Кварти')) else title[0][0], \"total_area\":title_list[1][:4]}\n",
    "    except:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f3a2575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(soup):\n",
    "    try:\n",
    "        dict_titles=dict()\n",
    "        informations=soup.find_all('li',class_=re.compile('params-paramsList__item-appQw'))\n",
    "        title_info=list(map(lambda x: x.text.strip().replace('\\xa0',''),informations))\n",
    "        titles=list(map(lambda x: x.find('span').text, informations))\n",
    "        for i in range(len(title_info)):\n",
    "            l=title_info[i].replace(titles[i],'')\n",
    "            dict_titles[titles[i].replace(': ','')]=l\n",
    "\n",
    "        return dict_titles\n",
    "    except:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "212bfbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_house(soup):\n",
    "    try:\n",
    "        dict_houses=dict()\n",
    "        house=soup.find_all('li', class_=re.compile('style-item-params-list-item-aXXql'))\n",
    "        titles_h=list(map(lambda x: x.find('span').text.replace('\\xa0',''), house))\n",
    "        house_info=list(map(lambda x: x.text.strip().replace('\\xa0',''),house))\n",
    "        for i in range(len(house_info)):\n",
    "            l=house_info[i].replace(titles_h[i],'')\n",
    "            dict_houses[titles_h[i].replace(':','')]=l\n",
    "        return dict_houses\n",
    "    except:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f3e028e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price(soup):\n",
    "    try:\n",
    "        price=soup.find('span', {'itemprop':'price'})\n",
    "        return price.text.replace('\\xa0','')\n",
    "    except:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09fda477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(soup):\n",
    "    try:\n",
    "        months = {\n",
    "        'декабря': '12',\n",
    "        'ноября': '11',\n",
    "        'октября': '10',\n",
    "        'сентября': '9',\n",
    "        'августа': '8',\n",
    "        'июля': '07',\n",
    "        'июня': '06',\n",
    "        'мая': '05',\n",
    "        'апреля': '04',\n",
    "        'марта': '03',\n",
    "        'февраля': '02',\n",
    "        'января': '01',\n",
    "        }\n",
    "        date_ = soup.find(\n",
    "                \"span\", {\"data-marker\": re.compile('item-view/item-date')}).get_text()\n",
    "        if 'сегодня' in date_:\n",
    "            date_ = f\"{date.today():%Y-%m-%d}\"\n",
    "        elif 'вчера' in date_:\n",
    "            date_ = f\"{date.today()-timedelta(days=1):%Y-%m-%d}\"\n",
    "        else:\n",
    "            day = re.search('[0-9]+', date_)[0]\n",
    "            if len(day) == 1:\n",
    "                day = '0'+day\n",
    "            for m in months:\n",
    "                if m in date_:\n",
    "                    month = months[m]\n",
    "                    break\n",
    "            if month in ['01', '02', '03','04']:\n",
    "                year = '2023'\n",
    "            else:\n",
    "                year = '2022'\n",
    "            date_ = year+'-'+month+'-'+day\n",
    "\n",
    "        return date_\n",
    "    except:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb54fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_address(soup):\n",
    "    d={}\n",
    "    try:\n",
    "        addr=soup.findAll('div', {'itemprop':re.compile(\"address\")})[0].next.next\n",
    "        \n",
    "        addr\n",
    "    except:\n",
    "        addr=''\n",
    "\n",
    "    return addr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b911cc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coords(soup):\n",
    "    try:\n",
    "        coords = soup.find(class_=re.compile('style-item-map-wrapper'))\n",
    "        return    coords['data-map-lat'],    coords['data-map-lon']\n",
    "    except:\n",
    "        return ('','')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899ce369",
   "metadata": {},
   "source": [
    "Функция объединения всех словарей, которые получаются на выходе функций, в один словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67639a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(und, title, inf,house, pr, address, date, link, coords):\n",
    "    d=dict()\n",
    "    try:\n",
    "        d['metro_name']=und['metro_name']\n",
    "    except KeyError:\n",
    "        d['metro_name']=''\n",
    "    try:\n",
    "        d['time_to_metro']=und['time_to_metro']\n",
    "    except KeyError:\n",
    "        d['time_to_metro']=''\n",
    "    try:\n",
    "        d['num_rooms']=title['num_rooms']\n",
    "    except KeyError:\n",
    "        d['num_rooms']=''\n",
    "    try:\n",
    "        d['total_area']=title['total_area']\n",
    "    except KeyError:\n",
    "        d['total_area']=''\n",
    "\n",
    "    try:\n",
    "        d['year_house']=house['Год постройки']\n",
    "    except KeyError:\n",
    "        d['year_house']=''\n",
    "\n",
    "    try:\n",
    "        d['kitchen']=inf['Площадь кухни']\n",
    "    except KeyError:\n",
    "        d['kitchen']=''\n",
    "    try:\n",
    "        d['repair']=inf['Ремонт']\n",
    "    except KeyError:\n",
    "        d['repair']=''\n",
    "    try:\n",
    "        d['price']=pr\n",
    "    except KeyError:\n",
    "        d['price']=''\n",
    "    try:\n",
    "        d['floors']=house['Этажей в доме']\n",
    "    except KeyError:\n",
    "        d['floors']=''\n",
    "    try:\n",
    "        d['num_floor']=inf['Этаж'].split()[0]\n",
    "    except KeyError:\n",
    "        d['num_floor']=''\n",
    "    try:\n",
    "        d['address']=address\n",
    "    except KeyError:\n",
    "        d['address']=''\n",
    "    try:\n",
    "        d['date']=date\n",
    "    except KeyError:\n",
    "        d['date']=''\n",
    "    \n",
    "    d['coord_width'], d['coord_len']=coords\n",
    "    \n",
    "    d['link']=f\"https://www.avito.ru{link}\"\n",
    "\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e889bb72",
   "metadata": {},
   "source": [
    "Класс адаптера и подключение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5517010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CIPHERS = \"\"\"ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-SHA256:AES256-SHA\"\"\"\n",
    "class TlsAdapter(HTTPAdapter):\n",
    "\n",
    "    def __init__(self, ssl_options=0, **kwargs):\n",
    "        self.ssl_options = ssl_options\n",
    "        super(TlsAdapter, self).__init__(**kwargs)\n",
    "\n",
    "    def init_poolmanager(self, *pool_args, **pool_kwargs):\n",
    "        ctx = ssl_.create_urllib3_context(\n",
    "            ciphers=CIPHERS, cert_reqs=ssl.CERT_REQUIRED, options=self.ssl_options)\n",
    "        self.poolmanager = PoolManager(\n",
    "            *pool_args, ssl_context=ctx, **pool_kwargs)\n",
    "\n",
    "\n",
    "session = requests.session()\n",
    "adapter = TlsAdapter(ssl.OP_NO_TLSv1 | ssl.OP_NO_TLSv1_1)\n",
    "session.mount(\"https://\", adapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798d4dc0",
   "metadata": {},
   "source": [
    "## Цикл парсинга"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d6a4a1",
   "metadata": {},
   "source": [
    "data- список словарей, которые в дальнейшем мы преобразуем в пандасовскую табличку. К сожалению ссылки на список объявлений нужно вставлять в ручную. В нашем случае это 6 ссылок- ссылка на студии, однокомнатные и тд., поэтому это не страшно. Приходится в ручную, т.к. Авито меняет расположение индикатора страницы в самой ссылке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4711a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for i in range(2,101):\n",
    "    \n",
    "    links=get_links(f\"https://www.avito.ru/moskva/kvartiry/prodam/vtorichka-ASgBAQICAUSSA8YQAUDmBxSMUg?f=ASgBAQICAUSSA8YQAkDmBxSMUsoIpIpZmqwBmKwBlqwBlKwBiFmGWYRZglmAWQ&p={i}&s=104\")\n",
    "        \n",
    "    \n",
    "    for j in links:\n",
    "        time.sleep(4)\n",
    "        \n",
    "        r = session.request('GET', f\"https://www.avito.ru{j}\")\n",
    "        soup = BeautifulSoup(r.text, \"lxml\")\n",
    "        dict_time=get_dict(get_undeground(soup),get_title(soup),get_info(soup),get_info_house(soup), get_price(soup), get_address(soup), get_date(soup), j, get_coords(soup))\n",
    "        if list(dict_time.values())==['', '', '', '', '', '', '', '', '', '']:\n",
    "\n",
    "            \n",
    "            time.sleep(10)\n",
    "            \n",
    "        else:\n",
    "            data.append(dict_time)\n",
    "        del soup,r\n",
    "    time.sleep(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3d91e5",
   "metadata": {},
   "source": [
    "## Сохранение данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcac3971",
   "metadata": {},
   "source": [
    "Функция преобразования списка словарей в пандасовскую таблицу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc028655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def into_pandas(data):\n",
    "    df=pd.DataFrame(columns=['metro_name',\n",
    "                             'time_to_metro',\n",
    "                             'num_rooms',\n",
    "                             'total_area',\n",
    "                             'year_house',\n",
    "                             'kitchen_area',\n",
    "                             'repair',\n",
    "                             'price',\n",
    "                             'floors',\n",
    "                             'num_floor', \n",
    "                             'address',\n",
    "                             'date',\n",
    "                             'coord_width',\n",
    "                             'coords_len',\n",
    "                             'link'])\n",
    "    for i in data:\n",
    "        df.loc[len(df)]=i.values()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e996af34",
   "metadata": {},
   "source": [
    "Сохраняем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12479016",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0=into_pandas(data)\n",
    "df_0.to_csv(r\"C:\\Users\\Stepan\\Desktop\\ВУЗ\\Клиент-серверные\\папка датафреймов\\1kretry.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
